{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PBFSCXtHjDDR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\saisa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Bidirectional, GRU\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "kUCikN22jMNo",
    "outputId": "33f695ae-d3da-47c2-ff5f-aca90ca70215"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is a truth universally acknowledged, that a single man in possession of a good fortune must be in want of a wife. However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered as the rightful property of some one or other of their daughters. My dear Mr. Bennet, said his lady to him one day, have you heard that Netherfield Park is let at last? Mr. Bennet replied '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file =open('ML_text_file_test.txt', \"r\", encoding = \"utf8\")\n",
    "# store file in list\n",
    "lines = []\n",
    "for i in file:\n",
    "    lines.append(i)\n",
    "\n",
    "# Convert list to string\n",
    "data = \"\"\n",
    "for i in lines:\n",
    "  data = ' '. join(lines)\n",
    "\n",
    "#replace unnecessary stuff with space\n",
    "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '').replace('“','').replace('”','')  #new line, carriage return, unicode character --> replace by space\n",
    "\n",
    "#remove unnecessary spaces\n",
    "data = data.split()\n",
    "data = ' '.join(data)\n",
    "data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AtSshaxNjV0D",
    "outputId": "613a0b07-d26b-4380-cf68-a55b17239601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1031\n",
      "The Length of sequences are:  4493\n",
      "Data:  [[ 18  21   5]\n",
      " [ 21   5 291]\n",
      " [  5 291 448]\n",
      " [291 448 292]\n",
      " [448 292  17]\n",
      " [292  17   5]\n",
      " [ 17   5 171]\n",
      " [  5 171  59]\n",
      " [171  59  10]\n",
      " [ 59  10 293]]\n",
      "Response:  [291 448 292  17   5 171  59  10 293   3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "\n",
    "# saving the tokenizer for predict function\n",
    "pickle.dump(tokenizer, open('token.pkl', 'wb'))\n",
    "\n",
    "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
    "sequence_data[:15]\n",
    "len(sequence_data)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)\n",
    "sequences = []\n",
    "\n",
    "for i in range(3, len(sequence_data)):\n",
    "    words = sequence_data[i-3:i+1]\n",
    "    sequences.append(words)\n",
    "\n",
    "print(\"The Length of sequences are: \", len(sequences))\n",
    "sequences = np.array(sequences)\n",
    "sequences[:10]\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in sequences:\n",
    "    X.append(i[0:3])\n",
    "    y.append(i[3])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(\"Data: \", X[:10])\n",
    "print(\"Response: \", y[:10])\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n6j0Y-eWjY0P",
    "outputId": "5913d9fc-d401-40cf-e490-4c3f2a2251f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\saisa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 3, 10)             10310     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 3, 1000)           4044000   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1000)              8004000   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1031)              1032031   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14091341 (53.75 MB)\n",
      "Trainable params: 14091341 (53.75 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=3))\n",
    "model.add(LSTM(1000, return_sequences=True))\n",
    "model.add(LSTM(1000))\n",
    "model.add(Dense(1000, activation=\"relu\"))\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 3, 10)             10310     \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 3, 2000)           8088000   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 2000)              24008000  \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1000)              2001000   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1031)              1032031   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35139341 (134.05 MB)\n",
      "Trainable params: 35139341 (134.05 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_BLSTM = Sequential()\n",
    "model_BLSTM.add(Embedding(vocab_size, 10, input_length=3))\n",
    "model_BLSTM.add(Bidirectional(LSTM(1000, return_sequences=True)))\n",
    "model_BLSTM.add(Bidirectional(LSTM(1000)))\n",
    "model_BLSTM.add(Dense(1000, activation=\"relu\"))\n",
    "model_BLSTM.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "model_BLSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 3, 10)             10310     \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 3, 1000)           3036000   \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 1000)              6006000   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1031)              1032031   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11085341 (42.29 MB)\n",
      "Trainable params: 11085341 (42.29 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_GRU = Sequential()\n",
    "model_GRU.add(Embedding(vocab_size, 10, input_length=3))\n",
    "model_GRU.add(GRU(1000, return_sequences=True))\n",
    "model_GRU.add(GRU(1000))\n",
    "model_GRU.add(Dense(1000, activation=\"relu\"))\n",
    "model_GRU.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "model_GRU.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "94E1mjAYjknB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "WARNING:tensorflow:From C:\\Users\\saisa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "70/71 [============================>.] - ETA: 0s - loss: 6.2441\n",
      "Epoch 1: loss improved from inf to 6.24377, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 6s 60ms/step - loss: 6.2438\n",
      "Epoch 2/70\n",
      " 1/71 [..............................] - ETA: 4s - loss: 5.9645"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saisa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/71 [============================>.] - ETA: 0s - loss: 5.8861\n",
      "Epoch 2: loss improved from 6.24377 to 5.88535, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 60ms/step - loss: 5.8853\n",
      "Epoch 3/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 5.8491\n",
      "Epoch 3: loss improved from 5.88535 to 5.84908, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 5.8491\n",
      "Epoch 4/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 5.8138\n",
      "Epoch 4: loss improved from 5.84908 to 5.81439, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 60ms/step - loss: 5.8144\n",
      "Epoch 5/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 5.7303\n",
      "Epoch 5: loss improved from 5.81439 to 5.73045, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 5.7304\n",
      "Epoch 6/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 5.5881\n",
      "Epoch 6: loss improved from 5.73045 to 5.58810, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 60ms/step - loss: 5.5881\n",
      "Epoch 7/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 5.3721\n",
      "Epoch 7: loss improved from 5.58810 to 5.37205, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 59ms/step - loss: 5.3720\n",
      "Epoch 8/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 5.1387\n",
      "Epoch 8: loss improved from 5.37205 to 5.13612, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 63ms/step - loss: 5.1361\n",
      "Epoch 9/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 4.9331\n",
      "Epoch 9: loss improved from 5.13612 to 4.93257, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 63ms/step - loss: 4.9326\n",
      "Epoch 10/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 4.7254\n",
      "Epoch 10: loss improved from 4.93257 to 4.72544, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 63ms/step - loss: 4.7254\n",
      "Epoch 11/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 4.5490\n",
      "Epoch 11: loss improved from 4.72544 to 4.54743, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 59ms/step - loss: 4.5474\n",
      "Epoch 12/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 4.3581\n",
      "Epoch 12: loss improved from 4.54743 to 4.35977, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 60ms/step - loss: 4.3598\n",
      "Epoch 13/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 4.1677\n",
      "Epoch 13: loss improved from 4.35977 to 4.17165, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 60ms/step - loss: 4.1717\n",
      "Epoch 14/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 4.0086\n",
      "Epoch 14: loss improved from 4.17165 to 4.01031, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 62ms/step - loss: 4.0103\n",
      "Epoch 15/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 3.8164\n",
      "Epoch 15: loss improved from 4.01031 to 3.81895, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 62ms/step - loss: 3.8190\n",
      "Epoch 16/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 3.6537\n",
      "Epoch 16: loss improved from 3.81895 to 3.65324, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 62ms/step - loss: 3.6532\n",
      "Epoch 17/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 3.4533\n",
      "Epoch 17: loss improved from 3.65324 to 3.45206, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 62ms/step - loss: 3.4521\n",
      "Epoch 18/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 3.2983\n",
      "Epoch 18: loss improved from 3.45206 to 3.29829, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 5s 75ms/step - loss: 3.2983\n",
      "Epoch 19/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 3.1285\n",
      "Epoch 19: loss improved from 3.29829 to 3.12854, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 5s 74ms/step - loss: 3.1285\n",
      "Epoch 20/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 2.9415\n",
      "Epoch 20: loss improved from 3.12854 to 2.94161, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 5s 75ms/step - loss: 2.9416\n",
      "Epoch 21/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 2.7587\n",
      "Epoch 21: loss improved from 2.94161 to 2.75962, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 5s 69ms/step - loss: 2.7596\n",
      "Epoch 22/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 2.5597\n",
      "Epoch 22: loss improved from 2.75962 to 2.56170, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 5s 64ms/step - loss: 2.5617\n",
      "Epoch 23/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 2.4111\n",
      "Epoch 23: loss improved from 2.56170 to 2.41000, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 2.4100\n",
      "Epoch 24/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 2.2305\n",
      "Epoch 24: loss improved from 2.41000 to 2.23054, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 2.2305\n",
      "Epoch 25/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 2.0785\n",
      "Epoch 25: loss improved from 2.23054 to 2.07853, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 2.0785\n",
      "Epoch 26/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 1.9157\n",
      "Epoch 26: loss improved from 2.07853 to 1.91386, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 62ms/step - loss: 1.9139\n",
      "Epoch 27/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.7569\n",
      "Epoch 27: loss improved from 1.91386 to 1.75692, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 1.7569\n",
      "Epoch 28/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.6292\n",
      "Epoch 28: loss improved from 1.75692 to 1.62924, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 62ms/step - loss: 1.6292\n",
      "Epoch 29/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.4722\n",
      "Epoch 29: loss improved from 1.62924 to 1.47215, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 1.4722\n",
      "Epoch 30/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 1.3162\n",
      "Epoch 30: loss improved from 1.47215 to 1.31741, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 1.3174\n",
      "Epoch 31/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 1.2096\n",
      "Epoch 31: loss improved from 1.31741 to 1.20881, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 62ms/step - loss: 1.2088\n",
      "Epoch 32/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 1.0877\n",
      "Epoch 32: loss improved from 1.20881 to 1.08811, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 1.0881\n",
      "Epoch 33/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.9966\n",
      "Epoch 33: loss improved from 1.08811 to 0.99722, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 62ms/step - loss: 0.9972\n",
      "Epoch 34/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.9276\n",
      "Epoch 34: loss improved from 0.99722 to 0.92763, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 0.9276\n",
      "Epoch 35/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.8318\n",
      "Epoch 35: loss improved from 0.92763 to 0.83179, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 62ms/step - loss: 0.8318\n",
      "Epoch 36/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.7264\n",
      "Epoch 36: loss improved from 0.83179 to 0.72643, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 0.7264\n",
      "Epoch 37/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.6437\n",
      "Epoch 37: loss improved from 0.72643 to 0.64349, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 0.6435\n",
      "Epoch 38/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.5734\n",
      "Epoch 38: loss improved from 0.64349 to 0.57351, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 0.5735\n",
      "Epoch 39/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.5389\n",
      "Epoch 39: loss improved from 0.57351 to 0.53791, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 0.5379\n",
      "Epoch 40/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.5033\n",
      "Epoch 40: loss improved from 0.53791 to 0.50299, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 0.5030\n",
      "Epoch 41/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.4882\n",
      "Epoch 41: loss improved from 0.50299 to 0.48875, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 0.4887\n",
      "Epoch 42/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.4295\n",
      "Epoch 42: loss improved from 0.48875 to 0.42951, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 63ms/step - loss: 0.4295\n",
      "Epoch 43/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.4087\n",
      "Epoch 43: loss improved from 0.42951 to 0.40873, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 0.4087\n",
      "Epoch 44/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.3549\n",
      "Epoch 44: loss improved from 0.40873 to 0.35491, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 0.3549\n",
      "Epoch 45/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.3102\n",
      "Epoch 45: loss improved from 0.35491 to 0.31019, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 62ms/step - loss: 0.3102\n",
      "Epoch 46/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.2833\n",
      "Epoch 46: loss improved from 0.31019 to 0.28305, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 0.2831\n",
      "Epoch 47/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.2502\n",
      "Epoch 47: loss improved from 0.28305 to 0.25019, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 0.2502\n",
      "Epoch 48/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.2389\n",
      "Epoch 48: loss improved from 0.25019 to 0.23853, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 62ms/step - loss: 0.2385\n",
      "Epoch 49/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.2195\n",
      "Epoch 49: loss improved from 0.23853 to 0.22074, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 0.2207\n",
      "Epoch 50/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.2387\n",
      "Epoch 50: loss did not improve from 0.22074\n",
      "71/71 [==============================] - 4s 62ms/step - loss: 0.2390\n",
      "Epoch 51/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.2132\n",
      "Epoch 51: loss improved from 0.22074 to 0.21350, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 5s 64ms/step - loss: 0.2135\n",
      "Epoch 52/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.2561\n",
      "Epoch 52: loss did not improve from 0.21350\n",
      "71/71 [==============================] - 4s 60ms/step - loss: 0.2564\n",
      "Epoch 53/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.2178\n",
      "Epoch 53: loss did not improve from 0.21350\n",
      "71/71 [==============================] - 5s 64ms/step - loss: 0.2178\n",
      "Epoch 54/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.2122\n",
      "Epoch 54: loss did not improve from 0.21350\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 0.2149\n",
      "Epoch 55/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.2282\n",
      "Epoch 55: loss did not improve from 0.21350\n",
      "71/71 [==============================] - 4s 59ms/step - loss: 0.2287\n",
      "Epoch 56/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.2352\n",
      "Epoch 56: loss did not improve from 0.21350\n",
      "71/71 [==============================] - 4s 59ms/step - loss: 0.2349\n",
      "Epoch 57/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.2317\n",
      "Epoch 57: loss did not improve from 0.21350\n",
      "71/71 [==============================] - 4s 59ms/step - loss: 0.2316\n",
      "Epoch 58/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.2371\n",
      "Epoch 58: loss did not improve from 0.21350\n",
      "71/71 [==============================] - 4s 59ms/step - loss: 0.2371\n",
      "Epoch 59/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.2615\n",
      "Epoch 59: loss did not improve from 0.21350\n",
      "71/71 [==============================] - 4s 59ms/step - loss: 0.2609\n",
      "Epoch 60/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.2577\n",
      "Epoch 60: loss did not improve from 0.21350\n",
      "71/71 [==============================] - 4s 59ms/step - loss: 0.2577\n",
      "Epoch 61/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.2235\n",
      "Epoch 61: loss did not improve from 0.21350\n",
      "71/71 [==============================] - 4s 60ms/step - loss: 0.2237\n",
      "Epoch 62/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1978\n",
      "Epoch 62: loss improved from 0.21350 to 0.19784, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 0.1978\n",
      "Epoch 63/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.1892\n",
      "Epoch 63: loss improved from 0.19784 to 0.19001, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 0.1900\n",
      "Epoch 64/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.1860\n",
      "Epoch 64: loss improved from 0.19001 to 0.18557, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 0.1856\n",
      "Epoch 65/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.1553\n",
      "Epoch 65: loss improved from 0.18557 to 0.15539, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 0.1554\n",
      "Epoch 66/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.1594\n",
      "Epoch 66: loss did not improve from 0.15539\n",
      "71/71 [==============================] - 4s 59ms/step - loss: 0.1598\n",
      "Epoch 67/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1575\n",
      "Epoch 67: loss did not improve from 0.15539\n",
      "71/71 [==============================] - 4s 59ms/step - loss: 0.1575\n",
      "Epoch 68/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.1453\n",
      "Epoch 68: loss improved from 0.15539 to 0.14493, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 0.1449\n",
      "Epoch 69/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1422\n",
      "Epoch 69: loss improved from 0.14493 to 0.14221, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 0.1422\n",
      "Epoch 70/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1401\n",
      "Epoch 70: loss improved from 0.14221 to 0.14014, saving model to Model_LSTM_Predictor.h5\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 0.1401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2fabedfbd50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"Model_LSTM_Predictor.h5\", monitor='loss', verbose=1, save_best_only=True)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))\n",
    "model.fit(X, y, epochs=70, batch_size=64, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FTOZf8r0kDZP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 6.2600\n",
      "Epoch 1: loss improved from inf to 6.26001, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 15s 161ms/step - loss: 6.2600\n",
      "Epoch 2/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 5.8329\n",
      "Epoch 2: loss improved from 6.26001 to 5.83287, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 160ms/step - loss: 5.8329\n",
      "Epoch 3/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 5.6935\n",
      "Epoch 3: loss improved from 5.83287 to 5.69350, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 160ms/step - loss: 5.6935\n",
      "Epoch 4/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 5.4901\n",
      "Epoch 4: loss improved from 5.69350 to 5.49005, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 160ms/step - loss: 5.4901\n",
      "Epoch 5/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 5.3433\n",
      "Epoch 5: loss improved from 5.49005 to 5.34335, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 160ms/step - loss: 5.3433\n",
      "Epoch 6/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 5.1966\n",
      "Epoch 6: loss improved from 5.34335 to 5.19658, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 162ms/step - loss: 5.1966\n",
      "Epoch 7/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 5.0384\n",
      "Epoch 7: loss improved from 5.19658 to 5.03841, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 12s 163ms/step - loss: 5.0384\n",
      "Epoch 8/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 4.8364\n",
      "Epoch 8: loss improved from 5.03841 to 4.83637, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 12s 162ms/step - loss: 4.8364\n",
      "Epoch 9/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 4.6794\n",
      "Epoch 9: loss improved from 4.83637 to 4.67939, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 12s 165ms/step - loss: 4.6794\n",
      "Epoch 10/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 4.4124\n",
      "Epoch 10: loss improved from 4.67939 to 4.41236, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 160ms/step - loss: 4.4124\n",
      "Epoch 11/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 4.1678\n",
      "Epoch 11: loss improved from 4.41236 to 4.16783, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 12s 163ms/step - loss: 4.1678\n",
      "Epoch 12/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 3.9229\n",
      "Epoch 12: loss improved from 4.16783 to 3.92289, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 12s 163ms/step - loss: 3.9229\n",
      "Epoch 13/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 3.6850\n",
      "Epoch 13: loss improved from 3.92289 to 3.68502, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 158ms/step - loss: 3.6850\n",
      "Epoch 14/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 3.4225\n",
      "Epoch 14: loss improved from 3.68502 to 3.42253, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 159ms/step - loss: 3.4225\n",
      "Epoch 15/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 3.1536\n",
      "Epoch 15: loss improved from 3.42253 to 3.15362, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 12s 166ms/step - loss: 3.1536\n",
      "Epoch 16/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 2.9413\n",
      "Epoch 16: loss improved from 3.15362 to 2.94129, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 162ms/step - loss: 2.9413\n",
      "Epoch 17/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 2.7223\n",
      "Epoch 17: loss improved from 2.94129 to 2.72235, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 12s 163ms/step - loss: 2.7223\n",
      "Epoch 18/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 2.4685\n",
      "Epoch 18: loss improved from 2.72235 to 2.46854, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 161ms/step - loss: 2.4685\n",
      "Epoch 19/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 2.2733\n",
      "Epoch 19: loss improved from 2.46854 to 2.27325, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 12s 162ms/step - loss: 2.2733\n",
      "Epoch 20/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 2.0848\n",
      "Epoch 20: loss improved from 2.27325 to 2.08481, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 12s 173ms/step - loss: 2.0848\n",
      "Epoch 21/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.8383\n",
      "Epoch 21: loss improved from 2.08481 to 1.83834, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 162ms/step - loss: 1.8383\n",
      "Epoch 22/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.6593\n",
      "Epoch 22: loss improved from 1.83834 to 1.65929, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 161ms/step - loss: 1.6593\n",
      "Epoch 23/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.5144\n",
      "Epoch 23: loss improved from 1.65929 to 1.51437, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 161ms/step - loss: 1.5144\n",
      "Epoch 24/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.3243\n",
      "Epoch 24: loss improved from 1.51437 to 1.32435, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 159ms/step - loss: 1.3243\n",
      "Epoch 25/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.1844\n",
      "Epoch 25: loss improved from 1.32435 to 1.18436, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 158ms/step - loss: 1.1844\n",
      "Epoch 26/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.0504\n",
      "Epoch 26: loss improved from 1.18436 to 1.05038, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 12s 163ms/step - loss: 1.0504\n",
      "Epoch 27/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.9332\n",
      "Epoch 27: loss improved from 1.05038 to 0.93321, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 12s 166ms/step - loss: 0.9332\n",
      "Epoch 28/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.8246\n",
      "Epoch 28: loss improved from 0.93321 to 0.82465, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 162ms/step - loss: 0.8246\n",
      "Epoch 29/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.7042\n",
      "Epoch 29: loss improved from 0.82465 to 0.70416, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 160ms/step - loss: 0.7042\n",
      "Epoch 30/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.6175\n",
      "Epoch 30: loss improved from 0.70416 to 0.61750, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 159ms/step - loss: 0.6175\n",
      "Epoch 31/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.5319\n",
      "Epoch 31: loss improved from 0.61750 to 0.53193, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 159ms/step - loss: 0.5319\n",
      "Epoch 32/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.4941\n",
      "Epoch 32: loss improved from 0.53193 to 0.49415, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 159ms/step - loss: 0.4941\n",
      "Epoch 33/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.4164\n",
      "Epoch 33: loss improved from 0.49415 to 0.41641, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 160ms/step - loss: 0.4164\n",
      "Epoch 34/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.3438\n",
      "Epoch 34: loss improved from 0.41641 to 0.34377, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 159ms/step - loss: 0.3438\n",
      "Epoch 35/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.3297\n",
      "Epoch 35: loss improved from 0.34377 to 0.32971, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 159ms/step - loss: 0.3297\n",
      "Epoch 36/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.4035\n",
      "Epoch 36: loss did not improve from 0.32971\n",
      "71/71 [==============================] - 11s 157ms/step - loss: 0.4035\n",
      "Epoch 37/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.3364\n",
      "Epoch 37: loss did not improve from 0.32971\n",
      "71/71 [==============================] - 11s 158ms/step - loss: 0.3364\n",
      "Epoch 38/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.2862\n",
      "Epoch 38: loss improved from 0.32971 to 0.28624, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 161ms/step - loss: 0.2862\n",
      "Epoch 39/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.2494\n",
      "Epoch 39: loss improved from 0.28624 to 0.24943, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 159ms/step - loss: 0.2494\n",
      "Epoch 40/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.2198\n",
      "Epoch 40: loss improved from 0.24943 to 0.21979, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 159ms/step - loss: 0.2198\n",
      "Epoch 41/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1875\n",
      "Epoch 41: loss improved from 0.21979 to 0.18753, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 159ms/step - loss: 0.1875\n",
      "Epoch 42/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1690\n",
      "Epoch 42: loss improved from 0.18753 to 0.16903, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 160ms/step - loss: 0.1690\n",
      "Epoch 43/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1601\n",
      "Epoch 43: loss improved from 0.16903 to 0.16010, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 12s 164ms/step - loss: 0.1601\n",
      "Epoch 44/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1573\n",
      "Epoch 44: loss improved from 0.16010 to 0.15725, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 161ms/step - loss: 0.1573\n",
      "Epoch 45/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1495\n",
      "Epoch 45: loss improved from 0.15725 to 0.14952, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 12s 167ms/step - loss: 0.1495\n",
      "Epoch 46/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1452\n",
      "Epoch 46: loss improved from 0.14952 to 0.14518, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 162ms/step - loss: 0.1452\n",
      "Epoch 47/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1418\n",
      "Epoch 47: loss improved from 0.14518 to 0.14175, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 161ms/step - loss: 0.1418\n",
      "Epoch 48/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1491\n",
      "Epoch 48: loss did not improve from 0.14175\n",
      "71/71 [==============================] - 11s 156ms/step - loss: 0.1491\n",
      "Epoch 49/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1374\n",
      "Epoch 49: loss improved from 0.14175 to 0.13739, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 162ms/step - loss: 0.1374\n",
      "Epoch 50/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1440\n",
      "Epoch 50: loss did not improve from 0.13739\n",
      "71/71 [==============================] - 11s 155ms/step - loss: 0.1440\n",
      "Epoch 51/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1399\n",
      "Epoch 51: loss did not improve from 0.13739\n",
      "71/71 [==============================] - 11s 161ms/step - loss: 0.1399\n",
      "Epoch 52/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1323\n",
      "Epoch 52: loss improved from 0.13739 to 0.13231, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 12s 162ms/step - loss: 0.1323\n",
      "Epoch 53/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1639\n",
      "Epoch 53: loss did not improve from 0.13231\n",
      "71/71 [==============================] - 11s 152ms/step - loss: 0.1639\n",
      "Epoch 54/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1936\n",
      "Epoch 54: loss did not improve from 0.13231\n",
      "71/71 [==============================] - 11s 153ms/step - loss: 0.1936\n",
      "Epoch 55/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.3377\n",
      "Epoch 55: loss did not improve from 0.13231\n",
      "71/71 [==============================] - 11s 152ms/step - loss: 0.3377\n",
      "Epoch 56/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.6902\n",
      "Epoch 56: loss did not improve from 0.13231\n",
      "71/71 [==============================] - 11s 153ms/step - loss: 0.6902\n",
      "Epoch 57/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.5764\n",
      "Epoch 57: loss did not improve from 0.13231\n",
      "71/71 [==============================] - 11s 156ms/step - loss: 0.5764\n",
      "Epoch 58/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.3515\n",
      "Epoch 58: loss did not improve from 0.13231\n",
      "71/71 [==============================] - 11s 156ms/step - loss: 0.3515\n",
      "Epoch 59/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.2160\n",
      "Epoch 59: loss did not improve from 0.13231\n",
      "71/71 [==============================] - 11s 152ms/step - loss: 0.2160\n",
      "Epoch 60/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1640\n",
      "Epoch 60: loss did not improve from 0.13231\n",
      "71/71 [==============================] - 11s 156ms/step - loss: 0.1640\n",
      "Epoch 61/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1422\n",
      "Epoch 61: loss did not improve from 0.13231\n",
      "71/71 [==============================] - 11s 153ms/step - loss: 0.1422\n",
      "Epoch 62/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1305\n",
      "Epoch 62: loss improved from 0.13231 to 0.13052, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 161ms/step - loss: 0.1305\n",
      "Epoch 63/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1182\n",
      "Epoch 63: loss improved from 0.13052 to 0.11819, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 161ms/step - loss: 0.1182\n",
      "Epoch 64/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1130\n",
      "Epoch 64: loss improved from 0.11819 to 0.11305, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 158ms/step - loss: 0.1130\n",
      "Epoch 65/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1104\n",
      "Epoch 65: loss improved from 0.11305 to 0.11042, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 160ms/step - loss: 0.1104\n",
      "Epoch 66/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0994\n",
      "Epoch 66: loss improved from 0.11042 to 0.09938, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 158ms/step - loss: 0.0994\n",
      "Epoch 67/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0982\n",
      "Epoch 67: loss improved from 0.09938 to 0.09815, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 11s 159ms/step - loss: 0.0982\n",
      "Epoch 68/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0954\n",
      "Epoch 68: loss improved from 0.09815 to 0.09543, saving model to Model_BLSTM_Predictor.h5\n",
      "71/71 [==============================] - 12s 162ms/step - loss: 0.0954\n",
      "Epoch 69/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0978\n",
      "Epoch 69: loss did not improve from 0.09543\n",
      "71/71 [==============================] - 11s 158ms/step - loss: 0.0978\n",
      "Epoch 70/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0962\n",
      "Epoch 70: loss did not improve from 0.09543\n",
      "71/71 [==============================] - 11s 154ms/step - loss: 0.0962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2fabed66a10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"Model_BLSTM_Predictor.h5\", monitor='loss', verbose=1, save_best_only=True)\n",
    "model_BLSTM.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))\n",
    "model_BLSTM.fit(X, y, epochs=70, batch_size=64, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 6.2220\n",
      "Epoch 1: loss improved from inf to 6.22250, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 6s 47ms/step - loss: 6.2225\n",
      "Epoch 2/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 5.8858\n",
      "Epoch 2: loss improved from 6.22250 to 5.88725, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 3s 49ms/step - loss: 5.8872\n",
      "Epoch 3/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 5.7491\n",
      "Epoch 3: loss improved from 5.88725 to 5.74906, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 3s 49ms/step - loss: 5.7491\n",
      "Epoch 4/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 5.5475\n",
      "Epoch 4: loss improved from 5.74906 to 5.54754, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 56ms/step - loss: 5.5475\n",
      "Epoch 5/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 5.2965\n",
      "Epoch 5: loss improved from 5.54754 to 5.29723, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 54ms/step - loss: 5.2972\n",
      "Epoch 6/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 5.0746\n",
      "Epoch 6: loss improved from 5.29723 to 5.07440, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 54ms/step - loss: 5.0744\n",
      "Epoch 7/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 4.8492\n",
      "Epoch 7: loss improved from 5.07440 to 4.84909, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 51ms/step - loss: 4.8491\n",
      "Epoch 8/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 4.5804\n",
      "Epoch 8: loss improved from 4.84909 to 4.58155, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 4.5815\n",
      "Epoch 9/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 4.3296\n",
      "Epoch 9: loss improved from 4.58155 to 4.32797, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 50ms/step - loss: 4.3280\n",
      "Epoch 10/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 4.0507\n",
      "Epoch 10: loss improved from 4.32797 to 4.05134, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 3s 49ms/step - loss: 4.0513\n",
      "Epoch 11/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 3.7544\n",
      "Epoch 11: loss improved from 4.05134 to 3.75438, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 3.7544\n",
      "Epoch 12/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 3.5038\n",
      "Epoch 12: loss improved from 3.75438 to 3.50379, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 3.5038\n",
      "Epoch 13/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 3.2201\n",
      "Epoch 13: loss improved from 3.50379 to 3.22316, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 3.2232\n",
      "Epoch 14/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 2.9184\n",
      "Epoch 14: loss improved from 3.22316 to 2.91722, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 2.9172\n",
      "Epoch 15/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 2.6343\n",
      "Epoch 15: loss improved from 2.91722 to 2.63317, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 2.6332\n",
      "Epoch 16/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 2.3175\n",
      "Epoch 16: loss improved from 2.63317 to 2.31751, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 3s 49ms/step - loss: 2.3175\n",
      "Epoch 17/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 2.0006\n",
      "Epoch 17: loss improved from 2.31751 to 2.00234, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 3s 49ms/step - loss: 2.0023\n",
      "Epoch 18/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.7130\n",
      "Epoch 18: loss improved from 2.00234 to 1.71302, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 3s 49ms/step - loss: 1.7130\n",
      "Epoch 19/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 1.4828\n",
      "Epoch 19: loss improved from 1.71302 to 1.48401, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 3s 49ms/step - loss: 1.4840\n",
      "Epoch 20/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.2241\n",
      "Epoch 20: loss improved from 1.48401 to 1.22410, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 3s 49ms/step - loss: 1.2241\n",
      "Epoch 21/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.9757\n",
      "Epoch 21: loss improved from 1.22410 to 0.97599, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 3s 49ms/step - loss: 0.9760\n",
      "Epoch 22/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.7810\n",
      "Epoch 22: loss improved from 0.97599 to 0.78125, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 50ms/step - loss: 0.7813\n",
      "Epoch 23/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.6198\n",
      "Epoch 23: loss improved from 0.78125 to 0.62061, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 49ms/step - loss: 0.6206\n",
      "Epoch 24/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.4999\n",
      "Epoch 24: loss improved from 0.62061 to 0.49992, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 49ms/step - loss: 0.4999\n",
      "Epoch 25/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.4311\n",
      "Epoch 25: loss improved from 0.49992 to 0.43040, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 50ms/step - loss: 0.4304\n",
      "Epoch 26/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.3318\n",
      "Epoch 26: loss improved from 0.43040 to 0.33375, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 54ms/step - loss: 0.3337\n",
      "Epoch 27/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.3097\n",
      "Epoch 27: loss improved from 0.33375 to 0.30972, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 55ms/step - loss: 0.3097\n",
      "Epoch 28/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.2631\n",
      "Epoch 28: loss improved from 0.30972 to 0.26311, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 55ms/step - loss: 0.2631\n",
      "Epoch 29/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.2230\n",
      "Epoch 29: loss improved from 0.26311 to 0.22241, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 56ms/step - loss: 0.2224\n",
      "Epoch 30/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.2050\n",
      "Epoch 30: loss improved from 0.22241 to 0.20506, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 57ms/step - loss: 0.2051\n",
      "Epoch 31/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1887\n",
      "Epoch 31: loss improved from 0.20506 to 0.18867, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 51ms/step - loss: 0.1887\n",
      "Epoch 32/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1717\n",
      "Epoch 32: loss improved from 0.18867 to 0.17174, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 3s 49ms/step - loss: 0.1717\n",
      "Epoch 33/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.1601\n",
      "Epoch 33: loss improved from 0.17174 to 0.16055, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 49ms/step - loss: 0.1605\n",
      "Epoch 34/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.1582\n",
      "Epoch 34: loss improved from 0.16055 to 0.15810, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 3s 49ms/step - loss: 0.1581\n",
      "Epoch 35/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.1440\n",
      "Epoch 35: loss improved from 0.15810 to 0.14372, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 49ms/step - loss: 0.1437\n",
      "Epoch 36/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.1336\n",
      "Epoch 36: loss improved from 0.14372 to 0.13330, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 50ms/step - loss: 0.1333\n",
      "Epoch 37/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1261\n",
      "Epoch 37: loss improved from 0.13330 to 0.12615, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 3s 49ms/step - loss: 0.1261\n",
      "Epoch 38/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1223\n",
      "Epoch 38: loss improved from 0.12615 to 0.12233, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 49ms/step - loss: 0.1223\n",
      "Epoch 39/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.1233\n",
      "Epoch 39: loss did not improve from 0.12233\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 0.1236\n",
      "Epoch 40/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.1224\n",
      "Epoch 40: loss improved from 0.12233 to 0.12206, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 3s 49ms/step - loss: 0.1221\n",
      "Epoch 41/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.1172\n",
      "Epoch 41: loss improved from 0.12206 to 0.11684, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 49ms/step - loss: 0.1168\n",
      "Epoch 42/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1146\n",
      "Epoch 42: loss improved from 0.11684 to 0.11458, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 50ms/step - loss: 0.1146\n",
      "Epoch 43/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.1188\n",
      "Epoch 43: loss did not improve from 0.11458\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 0.1184\n",
      "Epoch 44/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.1111\n",
      "Epoch 44: loss improved from 0.11458 to 0.11213, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 3s 49ms/step - loss: 0.1121\n",
      "Epoch 45/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1179\n",
      "Epoch 45: loss did not improve from 0.11213\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 0.1179\n",
      "Epoch 46/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1195\n",
      "Epoch 46: loss did not improve from 0.11213\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 0.1195\n",
      "Epoch 47/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.1321\n",
      "Epoch 47: loss did not improve from 0.11213\n",
      "71/71 [==============================] - 3s 47ms/step - loss: 0.1318\n",
      "Epoch 48/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1611\n",
      "Epoch 48: loss did not improve from 0.11213\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 0.1611\n",
      "Epoch 49/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.3646\n",
      "Epoch 49: loss did not improve from 0.11213\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 0.3647\n",
      "Epoch 50/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.8242\n",
      "Epoch 50: loss did not improve from 0.11213\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 0.8236\n",
      "Epoch 51/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.5816\n",
      "Epoch 51: loss did not improve from 0.11213\n",
      "71/71 [==============================] - 3s 49ms/step - loss: 0.5815\n",
      "Epoch 52/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.3094\n",
      "Epoch 52: loss did not improve from 0.11213\n",
      "71/71 [==============================] - 4s 53ms/step - loss: 0.3094\n",
      "Epoch 53/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.2033\n",
      "Epoch 53: loss did not improve from 0.11213\n",
      "71/71 [==============================] - 4s 50ms/step - loss: 0.2028\n",
      "Epoch 54/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.1427\n",
      "Epoch 54: loss did not improve from 0.11213\n",
      "71/71 [==============================] - 4s 52ms/step - loss: 0.1432\n",
      "Epoch 55/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.1337\n",
      "Epoch 55: loss did not improve from 0.11213\n",
      "71/71 [==============================] - 4s 55ms/step - loss: 0.1341\n",
      "Epoch 56/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.1129\n",
      "Epoch 56: loss did not improve from 0.11213\n",
      "71/71 [==============================] - 4s 55ms/step - loss: 0.1131\n",
      "Epoch 57/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.1026\n",
      "Epoch 57: loss improved from 0.11213 to 0.10290, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 51ms/step - loss: 0.1029\n",
      "Epoch 58/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0985\n",
      "Epoch 58: loss improved from 0.10290 to 0.09822, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 50ms/step - loss: 0.0982\n",
      "Epoch 59/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0937\n",
      "Epoch 59: loss improved from 0.09822 to 0.09393, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 51ms/step - loss: 0.0939\n",
      "Epoch 60/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0917\n",
      "Epoch 60: loss improved from 0.09393 to 0.09283, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 50ms/step - loss: 0.0928\n",
      "Epoch 61/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0987\n",
      "Epoch 61: loss did not improve from 0.09283\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 0.0987\n",
      "Epoch 62/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0944\n",
      "Epoch 62: loss did not improve from 0.09283\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 0.0944\n",
      "Epoch 63/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0913\n",
      "Epoch 63: loss improved from 0.09283 to 0.09150, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 50ms/step - loss: 0.0915\n",
      "Epoch 64/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0898\n",
      "Epoch 64: loss improved from 0.09150 to 0.09008, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 50ms/step - loss: 0.0901\n",
      "Epoch 65/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0865\n",
      "Epoch 65: loss improved from 0.09008 to 0.08675, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 3s 49ms/step - loss: 0.0868\n",
      "Epoch 66/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0880\n",
      "Epoch 66: loss did not improve from 0.08675\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 0.0880\n",
      "Epoch 67/70\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0903\n",
      "Epoch 67: loss did not improve from 0.08675\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 0.0903\n",
      "Epoch 68/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0868\n",
      "Epoch 68: loss improved from 0.08675 to 0.08657, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 50ms/step - loss: 0.0866\n",
      "Epoch 69/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0850\n",
      "Epoch 69: loss improved from 0.08657 to 0.08475, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 50ms/step - loss: 0.0848\n",
      "Epoch 70/70\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0814\n",
      "Epoch 70: loss improved from 0.08475 to 0.08185, saving model to Model_GRU_Predictor.h5\n",
      "71/71 [==============================] - 4s 51ms/step - loss: 0.0819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2fb0d170bd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"Model_GRU_Predictor.h5\", monitor='loss', verbose=1, save_best_only=True)\n",
    "model_GRU.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))\n",
    "model_GRU.fit(X, y, epochs=70, batch_size=64, callbacks=[checkpoint])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
